{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "В этом задании вам предстоит дообучить трансформерную модель для NER-задачи в различных форматах:\n",
    "\n",
    "1. Обучите NER-модель\n",
    "\n",
    "- Загрузите набор данных [Collection5](https://github.com/natasha/corus?tab=readme-ov-file#load_ne5) - **1 балл**\n",
    "- Разбейте набор данных на train/test части\n",
    "- Дообучите модель [rubert-tiny2](https://huggingface.co/cointegrated/rubert-tiny2) на train-части корпуса для решения NER-задачи, сделайте замеры качества NER-метрик до и после дообучения - **2 балла**\n",
    "\n",
    "2. Попробуйте улучшить качество модели следующими способами:\n",
    "- Предварительно дообучите на train-части в MLM режиме, а потом дообучите на NER-задачу - **2 балла**\n",
    "- Сгенерируйте синтетическую разметку* подходящего**, на ваш взгляд, новостного корпуса большой и умной моделью для русскоязычного NER***, а затем использовав ее для дообучения rubert-tiny2 вместе с основным набором данных - **2 балла**\n",
    "\n",
    "3. Финально сравните результаты различных подходов - **1 балл**\n",
    "\n",
    "*прогоните датасет через NER-модель, получите ее предсказания и используйте их в качестве резметки\n",
    "\n",
    "**Можно использовать уже знакомый вам датасет lenta-ru, объем данных лучше взять от 10_000 текстов\n",
    "\n",
    "***Например, можно взять модель модель DeepPavlov ner_collection3_bert. Инструкция по запуску есть в [документации](https://docs.deeppavlov.ai/en/master/features/models/NER.html)\n",
    "\n",
    "**Общее**\n",
    "\n",
    "- Принимаемые решения обоснованы (почему выбрана определенная архитектура/гиперпараметр/оптимизатор/преобразование и т.п.) - **1 балл**\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 0 - Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импортируем необходимые библиотеки и компоненты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "from corus import load_ne5, load_lenta\n",
    "from datasets import Dataset, ClassLabel, Sequence, concatenate_datasets\n",
    "from natasha import Segmenter, NewsEmbedding, NewsNERTagger, Doc\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "print(device)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фиксируем seed'ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 1 - Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_ne5(\"../data/hw_4/Collection5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ne5Markup(id='001', text='Россия рассчитывает на конструктивное воздействие США на Грузию\\r\\n\\r\\n04/08/2008 12:08\\r\\n\\r\\nМОСКВА, 4 авг - РИА Новости. Россия рассчитывает, что США воздействуют на Тбилиси в связи с обострением ситуации в зоне грузино-осетинского конфликта. Об этом статс-секретарь - заместитель министра иностранных дел России Григорий Карасин заявил в телефонном разговоре с заместителем госсекретаря США Дэниэлом Фридом.\\r\\n\\r\\n\"С российской стороны выражена глубокая озабоченность в связи с новым витком напряженности вокруг Южной Осетии, противозаконными действиями грузинской стороны по наращиванию своих вооруженных сил в регионе, бесконтрольным строительством фортификационных сооружений\", - говорится в сообщении.\\r\\n\\r\\n\"Россия уже призвала Тбилиси к ответственной линии и рассчитывает также на конструктивное воздействие со стороны Вашингтона\", - сообщил МИД России. ', spans=[Ne5Span(index='T1', type='GEOPOLIT', start=0, stop=6, text='Россия'), Ne5Span(index='T2', type='GEOPOLIT', start=50, stop=53, text='США'), Ne5Span(index='T3', type='GEOPOLIT', start=57, stop=63, text='Грузию'), Ne5Span(index='T4', type='LOC', start=87, stop=93, text='МОСКВА'), Ne5Span(index='T5', type='MEDIA', start=103, stop=114, text='РИА Новости'), Ne5Span(index='T6', type='GEOPOLIT', start=116, stop=122, text='Россия'), Ne5Span(index='T7', type='GEOPOLIT', start=141, stop=144, text='США'), Ne5Span(index='T8', type='GEOPOLIT', start=161, stop=168, text='Тбилиси'), Ne5Span(index='T9', type='GEOPOLIT', start=301, stop=307, text='России'), Ne5Span(index='T10', type='PER', start=308, stop=324, text='Григорий Карасин'), Ne5Span(index='T11', type='GEOPOLIT', start=383, stop=386, text='США'), Ne5Span(index='T12', type='PER', start=387, stop=402, text='Дэниэлом Фридом'), Ne5Span(index='T13', type='GEOPOLIT', start=505, stop=517, text='Южной Осетии'), Ne5Span(index='T14', type='GEOPOLIT', start=703, stop=709, text='Россия'), Ne5Span(index='T15', type='GEOPOLIT', start=723, stop=730, text='Тбилиси'), Ne5Span(index='T16', type='GEOPOLIT', start=815, stop=825, text='Вашингтона'), Ne5Span(index='T17', type='ORG', start=838, stop=841, text='МИД'), Ne5Span(index='T18', type='GEOPOLIT', start=842, stop=848, text='России')])\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальная предобработка данных\n",
    "\n",
    "* Будем решать задачу как задачу классификации - набор токенов к метке.\n",
    "* Для этого предобработаем наш текст до вида list токенов, list меток.\n",
    "* Метки представим по схеме BIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_markup_to_ner(item):\n",
    "    text = item.text\n",
    "    tokens = []\n",
    "    offsets = []\n",
    "    for match in re.finditer(r\"\\S+\", text):\n",
    "        tokens.append(match.group())\n",
    "        offsets.append((match.start(), match.end()))\n",
    "\n",
    "    labels = [\"O\"] * len(tokens)\n",
    "\n",
    "    for span in item.spans:\n",
    "        token_indices = [\n",
    "            i for i, (tstart, tend) in enumerate(offsets) if not (tend <= span.start or tstart >= span.stop)\n",
    "        ]\n",
    "        if token_indices:\n",
    "            labels[token_indices[0]] = \"B-\" + span.type\n",
    "            for idx in token_indices[1:]:\n",
    "                labels[idx] = \"I-\" + span.type\n",
    "\n",
    "    return {\"id\": item.id, \"tokens\": tokens, \"ner_tags\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [convert_markup_to_ner(item) for item in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset = Dataset.from_list(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set()\n",
    "for example in ner_dataset:\n",
    "    unique_labels.update(example[\"ner_tags\"])\n",
    "\n",
    "unique_labels = sorted(list(unique_labels))\n",
    "label_to_id = {label: i for i, label in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-GEOPOLIT': 0,\n",
       " 'B-LOC': 1,\n",
       " 'B-MEDIA': 2,\n",
       " 'B-ORG': 3,\n",
       " 'B-PER': 4,\n",
       " 'I-GEOPOLIT': 5,\n",
       " 'I-LOC': 6,\n",
       " 'I-MEDIA': 7,\n",
       " 'I-ORG': 8,\n",
       " 'I-PER': 9,\n",
       " 'O': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(example):\n",
    "    example[\"ner_tags\"] = [label_to_id[label] for label in example[\"ner_tags\"]]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b813daaa787b4e7894eeaacea8b30cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_dataset = ner_dataset.map(convert_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4a9a25a84e472cbccda2156850ee1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ner_dataset.features.copy()\n",
    "features[\"ner_tags\"] = Sequence(ClassLabel(names=unique_labels))\n",
    "ner_dataset = ner_dataset.cast(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '002', 'tokens': ['Комиссар', 'СЕ', 'критикует', 'ограничительную', 'политику', 'в', 'отношении', 'беженцев', 'в', 'европейских', 'странах', '05/08/2008', '10:32', 'МОСКВА,', '5', 'августа', '/Новости-Грузия/.', 'Проводимая', 'в', 'европейских', 'странах', 'ограничительная', 'политика', 'в', 'отношении', 'беженцев', 'нарушает', 'ряд', 'международных', 'стандартов,', 'в', 'частности,', 'право', 'на', 'воссоединение', 'семей,', 'заявляет', 'Комиссар', 'Совета', 'Европы', 'по', 'правам', 'человека', 'Томас', 'Хаммарберг', '(Thomas', 'Hammarberg)', 'в', 'размещенном', 'на', 'его', 'сайте', 'еженедельном', 'комментарии.', '\"Ограничительная', 'политика', 'в', 'отношении', 'беженцев', 'в', 'европейских', 'странах', 'уменьшает', 'возможности', 'воссоединения', 'разделенных', 'семей\",', '-', 'полагает', 'он.', 'По', 'сообщению', 'РИА', 'Новости,', 'Хаммарберг', 'констатирует,', 'что', 'в', 'последнее', 'время', '\"правительства', 'попытались', 'ограничить', 'приезд', 'близких', 'родственников', 'к', 'тем', 'беженцам,', 'которые', 'уже', 'проживают', 'в', 'стране\".', 'Комиссар', 'не', 'называет', 'конкретных', 'стран,', 'одновременно', 'отмечая,', 'что', 'в', 'ряде', 'случаев', 'подобная', 'линия', 'привела', '\"к', 'неоправданным', 'человеческим', 'страданиям,', 'когда', 'члены', 'семьи,', 'зависящие', 'друг', 'от', 'друга,', 'оказались', 'разделенными\".', '\"Такая', 'политика', 'противоречит', 'праву', 'на', 'воссоединение', 'семей,', 'как', 'это', 'предусмотрено', 'некоторыми', 'международными', 'стандартами\",', '-', 'замечает', 'он.', 'Комиссар', 'Совета', 'Европы', 'призывает', 'страны', 'учитывать', 'в', 'политике,', 'проводимой', 'в', 'отношении', 'беженцев,', 'положения', 'о', 'семье,', 'принятые', 'в', 'рамках', 'ООН', 'и', 'ЕС.'], 'ner_tags': [10, 3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 0, 10, 10, 2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 3, 8, 10, 10, 10, 4, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 2, 7, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 3, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 3, 10, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(ner_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизируем текст\n",
    "\n",
    "Оставим оригинальные метки для первого токена в последовательности, остальные отметим -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    all_labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a098efe434d4f549971e1d3dd06d028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = ner_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим данные на train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "test_dataset = tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2 - Обучение модели на задачу NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(unique_labels)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"cointegrated/rubert-tiny2\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем стандартные гиперпараметры для подобных моделей\n",
    "\n",
    "Кажется, что модель переобучится за 10 эпох, но transformers сохранит лучший артефакт за нас :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emperor\\Documents\\GitHub\\AI-2024-2_Sem\\DL NLP\\.venv\\lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/dbert\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем метрики классификации для sequence labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_predictions = [\n",
    "        [unique_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [unique_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emperor\\AppData\\Local\\Temp\\ipykernel_13768\\1377821198.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation before fine-tuning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.364283561706543, 'eval_model_preparation_time': 0.0021, 'eval_precision': 0.0151832055155318, 'eval_recall': 0.077500988533017, 'eval_f1': 0.02539189014121, 'eval_accuracy': 0.10832422481735028, 'eval_runtime': 0.4656, 'eval_samples_per_second': 429.544, 'eval_steps_per_second': 27.92}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation before fine-tuning:\")\n",
    "pre_training_results = trainer.evaluate()\n",
    "print(pre_training_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.566144</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.277066</td>\n",
       "      <td>0.247924</td>\n",
       "      <td>0.261686</td>\n",
       "      <td>0.835069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434527</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.381899</td>\n",
       "      <td>0.440490</td>\n",
       "      <td>0.409108</td>\n",
       "      <td>0.875511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361122</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.538299</td>\n",
       "      <td>0.605773</td>\n",
       "      <td>0.570047</td>\n",
       "      <td>0.908244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314260</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.603787</td>\n",
       "      <td>0.680902</td>\n",
       "      <td>0.640030</td>\n",
       "      <td>0.921935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279122</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.652441</td>\n",
       "      <td>0.713325</td>\n",
       "      <td>0.681526</td>\n",
       "      <td>0.930794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256713</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.675520</td>\n",
       "      <td>0.744168</td>\n",
       "      <td>0.708184</td>\n",
       "      <td>0.937353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243194</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.684814</td>\n",
       "      <td>0.756030</td>\n",
       "      <td>0.718662</td>\n",
       "      <td>0.940114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236398</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.763938</td>\n",
       "      <td>0.724274</td>\n",
       "      <td>0.940862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.233604</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.690519</td>\n",
       "      <td>0.763147</td>\n",
       "      <td>0.725019</td>\n",
       "      <td>0.941725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emperor\\Documents\\GitHub\\AI-2024-2_Sem\\DL NLP\\.venv\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.4705190124511719, metrics={'train_runtime': 15.3424, 'train_samples_per_second': 520.779, 'train_steps_per_second': 32.589, 'total_flos': 14148015982080.0, 'train_loss': 0.4705190124511719, 'epoch': 10.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation after fine-tuning:\n",
      "{'eval_loss': 0.2336038202047348, 'eval_model_preparation_time': 0.0021, 'eval_precision': 0.6905187835420393, 'eval_recall': 0.7631474891261368, 'eval_f1': 0.7250187828700226, 'eval_accuracy': 0.9417246735316114, 'eval_runtime': 0.5124, 'eval_samples_per_second': 390.31, 'eval_steps_per_second': 25.37, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation after fine-tuning:\")\n",
    "post_training_results = trainer.evaluate()\n",
    "print(post_training_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по эксперименту\n",
    "\n",
    "* Метрики после обучения значительно лучше, чем до, что очевидно.\n",
    "* Судя по val_loss модель немного недообучилась.\n",
    "* Получили очень высокий `accuracy` = 0.94, что понятно по метке 'O' - пустой, их большинство.\n",
    "* Получили вполне неплохой `f1` = 0.725 на тесте, будем в дальнейшем сравнивать этот показатель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 3 - Предобучим на MLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовим данные\n",
    "\n",
    "Склеим тексты, токенизируем их для нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74147c12acdd4f89a351fedf0d178852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def join_tokens(example):\n",
    "    example[\"text\"] = \" \".join(example[\"tokens\"])\n",
    "    return example\n",
    "\n",
    "\n",
    "mlm_train_dataset = train_dataset.map(join_tokens)\n",
    "mlm_test_dataset = test_dataset.map(join_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270174a0cbde4726a5fe0f7a83973fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_for_mlm(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "\n",
    "\n",
    "mlm_train_dataset = mlm_train_dataset.map(tokenize_for_mlm, batched=True)\n",
    "mlm_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "mlm_test_dataset = mlm_test_dataset.map(tokenize_for_mlm, batched=True)\n",
    "mlm_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим модель и обучим её\n",
    "\n",
    "Возьмём меньшее количество эпох, но чуть повысим LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
    "mlm_model = AutoModelForMaskedLM.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_training_args = TrainingArguments(\n",
    "    output_dir=\"../models/mlm/\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "mlm_trainer = Trainer(\n",
    "    model=mlm_model,\n",
    "    args=mlm_training_args,\n",
    "    train_dataset=mlm_train_dataset,\n",
    "    eval_dataset=mlm_test_dataset,\n",
    "    data_collator=mlm_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 00:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.945902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.821543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.891276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=171, training_loss=3.11281616924799, metrics={'train_runtime': 25.5505, 'train_samples_per_second': 105.555, 'train_steps_per_second': 6.693, 'total_flos': 20582750048256.0, 'train_loss': 3.11281616924799, 'epoch': 3.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод\n",
    "\n",
    "Успешно обучили модель MLM, проверим на NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем NER модель с момента чекпоинта MLM\n",
    "\n",
    "Оставим все оригинальные параметры. Возможно, это не оптимальный подход, но можно будет объективно сравнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ../models/mlm/checkpoint-171/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"../models/mlm/checkpoint-171/\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_training_args = TrainingArguments(\n",
    "    output_dir=\"../models/mlm/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "ner_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=ner_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation before NER fine-tuning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.375126600265503, 'eval_model_preparation_time': 0.0016, 'eval_precision': 0.027367955149011507, 'eval_recall': 0.14669829972321075, 'eval_f1': 0.04612993472179049, 'eval_accuracy': 0.12535235574987055, 'eval_runtime': 0.4322, 'eval_samples_per_second': 462.793, 'eval_steps_per_second': 30.082}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation before NER fine-tuning:\")\n",
    "print(ner_trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.898690</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.573792</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.249110</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>0.833688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.438180</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.469182</td>\n",
       "      <td>0.496639</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.878905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360574</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.622776</td>\n",
       "      <td>0.601375</td>\n",
       "      <td>0.908186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.313215</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.624777</td>\n",
       "      <td>0.691973</td>\n",
       "      <td>0.656660</td>\n",
       "      <td>0.924064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276746</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.662281</td>\n",
       "      <td>0.716489</td>\n",
       "      <td>0.688319</td>\n",
       "      <td>0.932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256119</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.668948</td>\n",
       "      <td>0.734282</td>\n",
       "      <td>0.700094</td>\n",
       "      <td>0.936490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243475</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.673506</td>\n",
       "      <td>0.739818</td>\n",
       "      <td>0.705106</td>\n",
       "      <td>0.938100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.237623</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.673797</td>\n",
       "      <td>0.747331</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.938963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.478200</td>\n",
       "      <td>0.234957</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.677996</td>\n",
       "      <td>0.749308</td>\n",
       "      <td>0.711871</td>\n",
       "      <td>0.939539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.478190673828125, metrics={'train_runtime': 15.0348, 'train_samples_per_second': 531.434, 'train_steps_per_second': 33.256, 'total_flos': 14148015982080.0, 'train_loss': 0.478190673828125, 'epoch': 10.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "* Модель немного недоучилась, ровно как и в первом случае.\n",
    "* Получили качество чуть хуже по `f1` = 0.712, но, вполне вероятно, при полном обучении, результаты были бы +- схожие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 4 - Аугментация с помощью большой модели NER\n",
    "\n",
    "* Используем 10_000 сэмплов lenta\n",
    "* В качестве модели возьмём NewsNERTagger из natasha, он имеет хорошее качество по бенчмаркам при невероятной по сравнению с конкурентами производительности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналогично предобработаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lenta = load_lenta(\"../data/raw/lenta-ru-news.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [\"title\", \"topic\", \"text\"]\n",
    "data_dict = {c: [] for c in target_columns}\n",
    "\n",
    "for item in data_lenta:\n",
    "    for column in target_columns:\n",
    "        data_dict[column].append(eval(f\"item.{column}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict)\n",
    "df = df.sample(10_000, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем намеченный natasha-сетап "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "embedding = NewsEmbedding()\n",
    "ner_tagger = NewsNERTagger(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_markup_natasha(example):\n",
    "    text = example[\"text\"]\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "\n",
    "    tokens = []\n",
    "    offsets = []\n",
    "    for match in re.finditer(r\"\\S+\", text):\n",
    "        tokens.append(match.group())\n",
    "        offsets.append((match.start(), match.end()))\n",
    "\n",
    "    labels = [\"O\"] * len(tokens)\n",
    "\n",
    "    for span in doc.spans:\n",
    "        token_indices = [i for i, (s, e) in enumerate(offsets) if not (e <= span.start or s >= span.stop)]\n",
    "        if token_indices:\n",
    "            labels[token_indices[0]] = \"B-\" + span.type\n",
    "            for idx in token_indices[1:]:\n",
    "                labels[idx] = \"I-\" + span.type\n",
    "\n",
    "    return {\"tokens\": tokens, \"ner_tags\": labels, \"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9852419fd5a245cb9e20986054a55f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markup_dataset = dataset.map(create_markup_natasha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приведём лейблы к виду нашего train датасета для объединения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce671a0455ac4abc87c25cec28d7347d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_list = [\n",
    "    \"B-GEOPOLIT\",\n",
    "    \"B-LOC\",\n",
    "    \"B-MEDIA\",\n",
    "    \"B-ORG\",\n",
    "    \"B-PER\",\n",
    "    \"I-GEOPOLIT\",\n",
    "    \"I-LOC\",\n",
    "    \"I-MEDIA\",\n",
    "    \"I-ORG\",\n",
    "    \"I-PER\",\n",
    "    \"O\",\n",
    "]\n",
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "\n",
    "def convert_tags(example):\n",
    "    example[\"ner_tags\"] = [label_map[tag] for tag in example[\"ner_tags\"]]\n",
    "    return example\n",
    "\n",
    "\n",
    "markup_dataset = markup_dataset.map(convert_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f17efcb930e44898cfa1c7f8453b3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = markup_dataset.features.copy()\n",
    "features[\"ner_tags\"] = Sequence(feature=ClassLabel(names=label_list))\n",
    "markup_dataset = markup_dataset.cast(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(batch):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        batch[\"tokens\"], truncation=True, padding=\"max_length\", is_split_into_words=True, max_length=128\n",
    "    )\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(batch[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(labels[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594c0cea91bd4ed596c9eb8eb96270e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markup_dataset = markup_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "markup_dataset = markup_dataset.remove_columns([\"title\", \"topic\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_dataset = concatenate_datasets([train_dataset, markup_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель\n",
    "\n",
    "Параметры и метрики аналогичны предыдущим для чистоты эксперимента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set()\n",
    "for example in combined_train_dataset:\n",
    "    unique_labels.update(example[\"ner_tags\"])\n",
    "unique_labels = sorted(list(unique_labels))\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"cointegrated/rubert-tiny2\", num_labels=len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_aug(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for pred, lab in zip(predictions, labels):\n",
    "        pred_labels = []\n",
    "        lab_labels = []\n",
    "        for p_val, l_val in zip(pred, lab):\n",
    "            if l_val != -100:\n",
    "                pred_labels.append(label_list[p_val])\n",
    "                lab_labels.append(label_list[l_val])\n",
    "        true_predictions.append(pred_labels)\n",
    "        true_labels.append(lab_labels)\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_training_args = TrainingArguments(\n",
    "    output_dir=\"../models/augmented/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "aug_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=aug_training_args,\n",
    "    train_dataset=combined_train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_aug,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation before Aug fine-tuning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.503415822982788, 'eval_model_preparation_time': 0.0, 'eval_precision': 0.019561815336463225, 'eval_recall': 0.09578544061302682, 'eval_f1': 0.032488628979857055, 'eval_accuracy': 0.06508063593732129, 'eval_runtime': 0.5807, 'eval_samples_per_second': 344.396, 'eval_steps_per_second': 22.386}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation before Aug fine-tuning:\")\n",
    "print(aug_trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6750' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6750/6750 02:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.346200</td>\n",
       "      <td>0.263587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.667791</td>\n",
       "      <td>0.932060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.216964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678821</td>\n",
       "      <td>0.706130</td>\n",
       "      <td>0.692207</td>\n",
       "      <td>0.937722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.182285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694239</td>\n",
       "      <td>0.720307</td>\n",
       "      <td>0.707033</td>\n",
       "      <td>0.941153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.167431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701548</td>\n",
       "      <td>0.729502</td>\n",
       "      <td>0.715252</td>\n",
       "      <td>0.944584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.158705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721275</td>\n",
       "      <td>0.745594</td>\n",
       "      <td>0.733233</td>\n",
       "      <td>0.947615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.147120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.746026</td>\n",
       "      <td>0.773180</td>\n",
       "      <td>0.759360</td>\n",
       "      <td>0.951618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.145638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752501</td>\n",
       "      <td>0.778161</td>\n",
       "      <td>0.765116</td>\n",
       "      <td>0.952877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.141626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.758442</td>\n",
       "      <td>0.783142</td>\n",
       "      <td>0.770594</td>\n",
       "      <td>0.954135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.139693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.955107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.139085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762593</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.775518</td>\n",
       "      <td>0.955221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6750, training_loss=0.06993983395894368, metrics={'train_runtime': 158.8719, 'train_samples_per_second': 679.73, 'train_steps_per_second': 42.487, 'total_flos': 191219555182080.0, 'train_loss': 0.06993983395894368, 'epoch': 10.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "* Модель опять немного недоучилась\n",
    "* Метрики качества значительно выше, особенно вырос `precision`\n",
    "* `f1` = 0.776 - это явный лидер по метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальные выводы\n",
    "\n",
    "* Смогли обучить весьма неплохую модель (если доучить, то был бы потенциал `f1` ~= 0.8)\n",
    "* Аугментация данных с помощью большой модели показала себя очень эффективно, что подтверждается личным практическим опытом\n",
    "* Предобучение MLM в данной задаче оказалось не очень полезно"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
