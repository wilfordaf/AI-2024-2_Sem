{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "В этом задании вам предстоит продолжить работу с датасетом lenta-ru-news для той же задачи - классификации текстов по топикам. Можно переиспользовать подготовленные данные из ДЗ 1 или загрузить их заново.\n",
    "\n",
    "1. Разделите датасет на обучающую, валидационную и тестовую выборки со стратификацией в пропорции 60/20/20. В качестве целевой переменной используйте атрибут `topic`\n",
    "2. Обучите word2vec-эмбеддинги с помощью библиотеки gensim - **2 балла**\n",
    "    - создайте модель для обучения на ваших данных, опишите, какими значениями вы инициализировали гиперпараметры модели, и почему\n",
    "    - визуально оцените внутреннее (intrinsic) качество получившихся эмбеддингов, используя методы gensim - doesnt_match, most_similar\n",
    "3. Загрузите предобученные эмбеддинги из navec и rusvectores (на ваш вкус) - **1 балл**\n",
    "4. Обучите модель `sklearn.linear_model.LogisticRegression` с тремя вариантами векторизации текстов и сравните их качество между собой на валидационной выборке: **2 балла**\n",
    "    - ваши эмбеддинги w2v\n",
    "    - предобученные эмбеддинги navec\n",
    "    - предобученные эмбеддинги rusvectores\n",
    "5. Попробуйте улучшить качество модели, взяв для ее обучения лучший набор эмбеддингов и используя его с взвешиванием через tf-idf. То есть, необходимо каждый текст представить в виде взвешенного усреднения эмбеддингов его слов, где весами являются соответствующие коэффициенты tf-idf - **2 балла**\n",
    "6. Финально сравните качество всех моделей на тестовой выборке - **1 балл**\n",
    "\n",
    "\n",
    "**Общее**\n",
    "\n",
    "- Принимаемые решения обоснованы (почему выбрана определенная архитектура/гиперпараметр/оптимизатор/преобразование и т.п.) - **1 балл**\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 0 - Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импортируем необходимые библиотеки и компоненты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "from typing import Any\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from navec import Navec\n",
    "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фиксируем seed'ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этап 1 - Загрузка и разделение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>topic</th><th>content</th><th>clean_content</th><th>encoded_topic</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Россия&quot;</td><td>&quot;ООН попросила Россию отложить …</td><td>&quot;оон попросить россия отложить …</td><td>10</td></tr><tr><td>&quot;Силовые структуры&quot;</td><td>&quot;Присяжные удалились для вынесе…</td><td>&quot;присяжный удалиться вынесение …</td><td>11</td></tr><tr><td>&quot;Спорт&quot;</td><td>&quot;Футболист ЦСКА посоветовал игр…</td><td>&quot;футболист цска посоветовать иг…</td><td>12</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌───────────────────┬───────────────────────────────┬──────────────────────────────┬───────────────┐\n",
       "│ topic             ┆ content                       ┆ clean_content                ┆ encoded_topic │\n",
       "│ ---               ┆ ---                           ┆ ---                          ┆ ---           │\n",
       "│ str               ┆ str                           ┆ str                          ┆ i64           │\n",
       "╞═══════════════════╪═══════════════════════════════╪══════════════════════════════╪═══════════════╡\n",
       "│ Россия            ┆ ООН попросила Россию отложить ┆ оон попросить россия         ┆ 10            │\n",
       "│                   ┆ …                             ┆ отложить …                   ┆               │\n",
       "│ Силовые структуры ┆ Присяжные удалились для       ┆ присяжный удалиться          ┆ 11            │\n",
       "│                   ┆ вынесе…                       ┆ вынесение …                  ┆               │\n",
       "│ Спорт             ┆ Футболист ЦСКА посоветовал    ┆ футболист цска посоветовать  ┆ 12            │\n",
       "│                   ┆ игр…                          ┆ иг…                          ┆               │\n",
       "└───────────────────┴───────────────────────────────┴──────────────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(\"../data/processed/hw_1.parquet\")\n",
    "\n",
    "print(df.shape)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (60000, 4), val size: (20000, 4), test size (20000, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df[\"encoded_topic\"], random_state=RANDOM_STATE)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"encoded_topic\"], random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Train size: {train_df.shape}, val size: {val_df.shape}, test size {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизируем тексты для W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.with_columns(pl.col(\"clean_content\").str.split(\" \").alias(\"tokens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>topic</th><th>content</th><th>clean_content</th><th>encoded_topic</th><th>tokens</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;Бывший СССР&quot;</td><td>&quot;В ДНР продемонстрировали «отве…</td><td>&quot;днр продемонстрировать ответ а…</td><td>2</td><td>[&quot;днр&quot;, &quot;продемонстрировать&quot;, … &quot;беспилотник&quot;]</td></tr><tr><td>&quot;Мир&quot;</td><td>&quot;Журналист The Sun пронес муляж…</td><td>&quot;журналист пронести муляж бомба…</td><td>7</td><td>[&quot;журналист&quot;, &quot;пронести&quot;, … &quot;добавлять&quot;]</td></tr><tr><td>&quot;Россия&quot;</td><td>&quot;Прокуратура начала проверку в …</td><td>&quot;прокуратура начать проверка си…</td><td>10</td><td>[&quot;прокуратура&quot;, &quot;начать&quot;, … &quot;налог&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌─────────────┬──────────────────────┬──────────────────────┬───────────────┬──────────────────────┐\n",
       "│ topic       ┆ content              ┆ clean_content        ┆ encoded_topic ┆ tokens               │\n",
       "│ ---         ┆ ---                  ┆ ---                  ┆ ---           ┆ ---                  │\n",
       "│ str         ┆ str                  ┆ str                  ┆ i64           ┆ list[str]            │\n",
       "╞═════════════╪══════════════════════╪══════════════════════╪═══════════════╪══════════════════════╡\n",
       "│ Бывший СССР ┆ В ДНР                ┆ днр                  ┆ 2             ┆ [\"днр\", \"продемонстр │\n",
       "│             ┆ продемонстрировали   ┆ продемонстрировать   ┆               ┆ ировать\", …          │\n",
       "│             ┆ «отве…               ┆ ответ а…             ┆               ┆                      │\n",
       "│ Мир         ┆ Журналист The Sun    ┆ журналист пронести   ┆ 7             ┆ [\"журналист\",        │\n",
       "│             ┆ пронес муляж…        ┆ муляж бомба…         ┆               ┆ \"пронести\", … \"д…    │\n",
       "│ Россия      ┆ Прокуратура начала   ┆ прокуратура начать   ┆ 10            ┆ [\"прокуратура\",      │\n",
       "│             ┆ проверку в …         ┆ проверка си…         ┆               ┆ \"начать\", … \"н…      │\n",
       "└─────────────┴──────────────────────┴──────────────────────┴───────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2 - Обучение W2V модели\n",
    "\n",
    "Возьмём стандартные параметры для обучения, но сделаем чуть меньше эпох для ускорения процесса обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=train_df[\"tokens\"].to_list(),\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=1,\n",
    "    epochs=5,\n",
    "    negative=5,\n",
    "    seed=RANDOM_STATE,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"../models/w2v_1203.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова, похожие на 'март':\n",
      "[('апрель', 0.8195676803588867), ('февраль', 0.7926869988441467), ('май', 0.7555468082427979), ('декабрь', 0.7477976083755493), ('январь', 0.729356050491333)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Слова, похожие на 'март':\")\n",
    "print(w2v_model.wv.most_similar(\"март\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово, не подходящее в группе:\n",
      "игра\n"
     ]
    }
   ],
   "source": [
    "print(\"Слово, не подходящее в группе:\")\n",
    "print(w2v_model.wv.doesnt_match([\"март\", \"декабрь\", \"январь\", \"игра\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 3 - Загрузим предобученные эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec_model = Navec.load(\"../models/navec/navec_hudlit_v1_12B_500K_300d_100q.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8772458"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec_model.sim(\"март\", \"апрель\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusvectores_model = KeyedVectors.load_word2vec_format(\"../models/rusvectors/model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "\n",
    "def transform_word(word: str) -> str:\n",
    "    doc = Doc(word)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    if doc.tokens:\n",
    "        token = doc.tokens[0]\n",
    "        if token.pos:\n",
    "            return f\"{token.text}_{token.pos}\"\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель_NOUN', 0.9572353959083557),\n",
       " ('февраль_NOUN', 0.9567031264305115),\n",
       " ('ноябрь_NOUN', 0.9381636381149292),\n",
       " ('октябрь_NOUN', 0.9329459071159363),\n",
       " ('май_NOUN', 0.9289151430130005)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusvectores_model.most_similar(transform_word(\"март\"), topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 4 - Обучение моделей\n",
    "\n",
    "Напишем методы для получения эмбеддинга предложения - берём среднее по эмбеддингам слов, наиболее популярный подход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_embedding_mean(tokens: list[str], emb_model: Any, apply=lambda x: x) -> npt.NDArray[np.float32]:\n",
    "    vecs = [emb_model[apply(word)] for word in tokens if apply(word) in emb_model]\n",
    "    if not vecs:\n",
    "        return np.zeros(emb_model.vector_size)\n",
    "\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(df: pl.DataFrame, emb_model: Any, column_name: str, apply=lambda x: x) -> npt.NDArray[np.float32]:\n",
    "    embeddings = []\n",
    "    if column_name not in df.columns:\n",
    "        df = df.with_columns(pl.col(\"clean_content\").str.split(\" \").alias(\"tokens\"))\n",
    "\n",
    "    for tokens in tqdm(df[column_name].to_list()):\n",
    "        embeddings.append(document_embedding_mean(tokens, emb_model, apply))\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = get_embeddings(train_df, w2v_model.wv, \"tokens\")\n",
    "X_val_w2v = get_embeddings(val_df, w2v_model.wv, \"tokens\")\n",
    "X_test_w2v = get_embeddings(test_df, w2v_model.wv, \"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_navec = get_embeddings(train_df, navec_model, \"tokens\")\n",
    "X_val_navec = get_embeddings(val_df, navec_model, \"tokens\")\n",
    "X_test_navec = get_embeddings(test_df, navec_model, \"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748af608c73e426ab5e7403fcf06a51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4117070044c04250bbaec821c8c018be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379e3f709dab4f4385c51301086b7b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_rusvect = get_embeddings(train_df, rusvectores_model, \"tokens\", transform_word)\n",
    "X_val_rusvect = get_embeddings(val_df, rusvectores_model, \"tokens\", transform_word)\n",
    "X_test_rusvect = get_embeddings(test_df, rusvectores_model, \"tokens\", transform_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train_rusvect.npy\", X_train_rusvect)\n",
    "np.save(\"X_val_rusvect.npy\", X_val_rusvect)\n",
    "np.save(\"X_test_rusvect.npy\", X_test_rusvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"encoded_topic\"].to_list()\n",
    "y_val = val_df[\"encoded_topic\"].to_list()\n",
    "y_test = test_df[\"encoded_topic\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы для обучения модели\n",
    "\n",
    "Используем cv=3 и параметры из hw_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_cv(X, y, cv=3):\n",
    "    clf = LogisticRegression(solver=\"lbfgs\", C=10, max_iter=1000, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(\"CV scores:\", scores)\n",
    "    print(\"Average CV accuracy:\", scores.mean())\n",
    "    clf.fit(X, y)\n",
    "    return scores.mean(), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [0.7939 0.7943 0.7911]\n",
      "Average CV accuracy: 0.7931\n",
      "Accuracy (свой w2v): 0.793\n",
      "Accuracy (свой w2v): 0.795\n"
     ]
    }
   ],
   "source": [
    "acc_w2v, clf_w2v = train_evaluate_cv(X_train_w2v, y_train)\n",
    "print(f\"Accuracy (свой w2v): {acc_w2v:.3f}\")\n",
    "val_result_w2v = clf_w2v.predict(X_val_w2v)\n",
    "print(f\"Accuracy (свой w2v) валидация: {accuracy_score(y_val, val_result_w2v):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [0.7645  0.76365 0.7627 ]\n",
      "Average CV accuracy: 0.7636166666666667\n",
      "Accuracy (navec): 0.764\n",
      "Accuracy (navec) валидация: 0.771\n"
     ]
    }
   ],
   "source": [
    "acc_navec, clf_navec = train_evaluate_cv(X_train_navec, y_train)\n",
    "print(f\"Accuracy (navec): {acc_navec:.3f}\")\n",
    "val_result_navec = clf_navec.predict(X_val_navec)\n",
    "print(f\"Accuracy (navec) валидация: {accuracy_score(y_val, val_result_navec):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [0.74305 0.7376  0.7383 ]\n",
      "Average CV accuracy: 0.73965\n",
      "Accuracy (rusvectores): 0.740\n",
      "Accuracy (navec) валидация: 0.748\n"
     ]
    }
   ],
   "source": [
    "acc_rusvect, clf_rusvect = train_evaluate_cv(X_train_rusvect, y_train)\n",
    "print(f\"Accuracy (rusvectores): {acc_rusvect:.3f}\")\n",
    "val_result_rusvect = clf_rusvect.predict(X_val_rusvect)\n",
    "print(f\"Accuracy (navec) валидация: {accuracy_score(y_val, val_result_rusvect):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "Несколько удивительно, но наша модель W2V показала себя лучше, чем предобученные на большом корпусе варианты.\n",
    "\n",
    "Возможно, отобранные новости имеют специфический домен или наша предобработка нерелевантна для других векторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 5 - Улучшение результатов с помощью TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(train_df[\"clean_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_document_embedding(\n",
    "    text: str,\n",
    "    emb_model: Any,\n",
    "    tfidf_vectorizer: TfidfVectorizer,\n",
    ") -> npt.NDArray[np.float32]:\n",
    "    tokens = text.split()\n",
    "    tfidf_vec = tfidf_vectorizer.transform([\" \".join(tokens)]).toarray()[0]\n",
    "\n",
    "    word2tfidf = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in tfidf_vectorizer.vocabulary_:\n",
    "            idx = tfidf_vectorizer.vocabulary_[token]\n",
    "            word2tfidf[token] = tfidf_vec[idx]\n",
    "\n",
    "    vecs, weights = [], []\n",
    "    model_vocab = emb_model.wv if hasattr(emb_model, \"wv\") else emb_model\n",
    "    for token in tokens:\n",
    "        if token in model_vocab and token in word2tfidf:\n",
    "            vecs.append(model_vocab[token] * word2tfidf[token])\n",
    "            weights.append(word2tfidf[token])\n",
    "\n",
    "    if not vecs:\n",
    "        return np.zeros(emb_model.vector_size)\n",
    "\n",
    "    return np.sum(vecs, axis=0) / np.sum(weights)\n",
    "\n",
    "\n",
    "def get_weighted_embeddings(\n",
    "    df: pl.DataFrame,\n",
    "    emb_model: Any,\n",
    "    tfidf_vectorizer: TfidfVectorizer,\n",
    ") -> npt.NDArray[np.float32]:\n",
    "    embeddings = []\n",
    "    for text in df[\"clean_content\"]:\n",
    "        embeddings.append(weighted_document_embedding(text, emb_model, tfidf_vectorizer))\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_tfidf = get_weighted_embeddings(train_df, w2v_model, tfidf)\n",
    "X_val_w2v_tfidf = get_weighted_embeddings(val_df, w2v_model, tfidf)\n",
    "X_test_w2v_tfidf = get_weighted_embeddings(test_df, w2v_model, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [0.767  0.7692 0.7665]\n",
      "Average CV accuracy: 0.7675666666666666\n"
     ]
    }
   ],
   "source": [
    "acc_w2v_tfidf, clf_w2v_tfidf = train_evaluate_cv(X_train_w2v_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (свой w2v + TFIDF): 0.766\n"
     ]
    }
   ],
   "source": [
    "val_result_w2v_tfidf = clf_w2v_tfidf.predict(X_val_w2v_tfidf)\n",
    "print(f\"Accuracy (свой w2v + TFIDF): {accuracy_score(y_val, val_result_w2v_tfidf):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "К сожалению, подход с TFIDF не улучшил качество эмбеддингов предложений. \n",
    "\n",
    "Можно сделать вывод, что даже простая эвристика в виде mean бывает весьма эффективна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Этап 6 - Финальная оценка на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(clf: Any, X_test: npt.NDArray[np.float32], y_test: npt.NDArray[np.float32]) -> float:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_w2v = evaluate_on_test(clf_w2v, X_test_w2v, y_test)\n",
    "test_acc_navec = evaluate_on_test(clf_navec, X_test_navec, y_test)\n",
    "test_acc_rusvect = evaluate_on_test(clf_rusvect, X_test_rusvect, y_test)\n",
    "test_acc_navec_tfidf = evaluate_on_test(clf_w2v_tfidf, X_test_w2v_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (свой w2v): 0.797\n",
      "Test Accuracy (navec): 0.769\n",
      "Test Accuracy (rusvectores): 0.746\n",
      "Test Accuracy (navec + TFIDF): 0.766\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy (свой w2v): {test_acc_w2v:.3f}\")\n",
    "print(f\"Test Accuracy (navec): {test_acc_navec:.3f}\")\n",
    "print(f\"Test Accuracy (rusvectores): {test_acc_rusvect:.3f}\")\n",
    "print(f\"Test Accuracy (navec + TFIDF): {test_acc_navec_tfidf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "На отложенной тестовой выборке победителем по качеству также является наш обученный W2V без TFIDF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
